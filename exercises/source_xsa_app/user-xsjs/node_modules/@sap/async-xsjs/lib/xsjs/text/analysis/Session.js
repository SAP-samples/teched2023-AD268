'use strict';

var ta = require('@sap/textanalysis');
var bufferUtils = require('../../../utils/buffer-utils');

module.exports = Session;

function Session($db, params) {
  this.configuration = params.configuration;
  this.client = (async () => { await $db.getConnection()._client; })();
  this.schema = $db._dbReqOptions._globalOptions.schema;
}

Session.prototype.analyze = async function (params) {
  return await analyze(this, params);
};

function analyze(session, params) {
  var values = normalizeInput(params);
  values.CONFIGURATION_SCHEMA_NAME = session.schema;
  values.CONFIGURATION = session.configuration;
  return new Promise ((resolve, reject) => {

    ta.analyze(values, session.client, function (err, parameters, rows) {
      if (err) {
        return reject(err);
      }
      var tokens = [], entities = [], metadata = [], grammaticalRoles = [];
      if (rows) {
        for (var i = 0; i < rows.length; i++) {
          var row = rows[i];
          if (row.RULE === 'Entity Extraction') {
            var entity = {
              id: row.COUNTER,
              text: row.TOKEN,
              normalizedForm: row.NORMALIZED,
              labelPath: row.TYPE,
              offset: row.OFFSET,
              paragraph: row.PARAGRAPH,
              sentence: row.SENTENCE,
              parent: row.PARENT
            };
            entities.push(entity);
          }
          else if (row.RULE === 'LXP') {
            var token = {
              token: row.TOKEN,
              normalizedToken: row.NORMALIZED,
              partOfSpeech: row.TYPE,
              offset: row.OFFSET,
              paragraph: row.PARAGRAPH,
              sentence: row.SENTENCE
              // TODO: stems
            };
            tokens.push(token);
          }
          else if (row.RULE === 'Grammatical Role') {
            var grammaticalRoleGovernor = {
              id: row.PARENT,
              dependencyType: row.TYPE
            };
            var grammaticalRole = {
              id: row.COUNTER,
              offset: row.OFFSET,
              paragraph: row.PARAGRAPH,
              sentence: row.SENTENCE,
              text: row.TOKEN,
              governors: [grammaticalRoleGovernor]
            };
            grammaticalRoles.push(grammaticalRole);
          }
          else if (row.RULE === 'Metadata') {
            var meta = {
              id: row.COUNTER,
              token: row.TOKEN,
              tokenType: row.TYPE,
              offset: row.OFFSET,
              paragraph: row.PARAGRAPH,
              parent: row.PARENT
            };
            metadata.push(meta);
          }
        }
      }
      return resolve({
        language: parameters.LANGUAGE_CODE,
        mimeType: parameters.MIME_TYPE,
        textSize: 0, // not returned by TA_ANALYZE
        plaintext: parameters.PLAINTEXT,
        tokens: tokens,
        entities: entities,
        metadata: metadata,
        grammaticalRoles: grammaticalRoles
      });
    });
  });
}

function normalizeInput(params) {
  var mappings = {
    'inputDocumentText': 'DOCUMENT_TEXT',
    'language': 'LANGUAGE_CODE',
    'mimeType': 'MIME_TYPE',
    'tokenSeparators': 'TOKEN_SEPARATORS',
    'languageDetection': 'LANGUAGE_DETECTION'
  };

  var values = {
    RETURN_PLAINTEXT: params.includePlainText ? 1 : 0
  };

  Object.keys(mappings).forEach(function (xscProp) {
    if (params.hasOwnProperty(xscProp) && params[xscProp] !== undefined) {
      var prop = mappings[xscProp];
      values[prop] = params[xscProp];
    }
  });

  if (params.inputDocumentBinaryContent) {
    values.DOCUMENT_BINARY = extractBinary(params.inputDocumentBinaryContent);
  }

  return values;
}

function extractBinary(binContent) {
  return bufferUtils.isBinary(binContent) ? bufferUtils.toBuffer(binContent) : Buffer.from(binContent);
}
